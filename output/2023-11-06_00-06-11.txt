Recognized Text:
We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet: When scaled to 680,000 hours of multilingual and multitask supervision; the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zeroshot transfer setting without the need for any finetuning: When compared to humans; the models approach their accuracy and robustness We are releasing models and inference code to serve @5 foundation for further work on robust speech processing:

Response Text:
Tusoma obusobozi bw'enkola z'okulongoosa okwogera nga butendekeddwa buteekebwako okuteeberezebwa obungi obuwandiike bw'amaloboozi ku yintaneeti: Bw'ogeraageranyizibwa ku ssaawa 680,000 ez'ennimi ezitali zimu n'obuwuka obulala. Okulaba; ebivuddemu ebyokulabirako bisobola okuyamba obulungi ku bulagirizi obukwata ku mutindo era nga batera okuvuganya n'ebivudde mu kulondoola mu bujjuvu wabula mu kukyusa amasasi awatali bwetaavu bwa ffineesi yonna. : Bw'ogeraageranya n'abantu; enkola ezo zituukirira obutuufu bwazo n'obutebenkevu bwazo Tufulumya enkola n'enkola ey'obutebenkevu okuweereza @5 omusingi gw'okwongera okukola ku kutereeza okwogera okw'omutindo: